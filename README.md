# VAE from Scratch for Fashion Image Generation

 
**Summary:** Learn a clean latent representation of Fashionâ€‘MNIST with a **Variational Autoencoder (VAE)** (and its Î²â€‘VAE variant) and generate realistic fashion images.  
**Highlights**

- âœ¨ *Fromâ€‘scratch* PyTorch implementation (no Lightning)  
- ðŸ” **Hyperparameter search** with **Rayâ€¯Tune** + ASHA/HyperBand (latentâ€¯dim, LR, batchâ€¯size)  
- ðŸ—ï¸ **Scaled MLOps pipeline**: modular code, checkpoints, TensorBoard, SLURMâ€‘ready  
- ðŸ“ˆ Reproducible results & bestâ€‘config plot  

---

## Dataset

> **Fashionâ€‘MNIST** (Zalando Research) â€“ 70â€¯000 28Ã—28 grayscale images across 10 clothing classes (Tâ€‘shirt, trouser, sneaker, â€¦).  

---

## Model Architecture

| Part        | Layer(s) | Notes |
|-------------|----------|-------|
| **Encoder** | Convâ€¯(1â†’32,â€¯3Ã—3) â†’ ReLU â†’ Convâ€¯(32â†’64,â€¯3Ã—3) â†’ ReLU â†’ Flatten â†’ FC â†’ **Î¼**, **logâ€¯ÏƒÂ²** | |
| **Latent**  | 32â€‘D vector sampled via reparameterization trick | Latent dim swept over {16,â€¯32,â€¯64} |
| **Decoder** | FC â†’ reshape â†’ ConvTâ€¯(64â†’32) â†’ ReLU â†’ ConvTâ€¯(32â†’1) â†’ Sigmoid | |
| **Loss**    | **Binary Crossâ€‘Entropy** + **KLâ€‘divergence** | Î²â€‘VAE multiplies KL by Î² |

---

## Repository Structure

```text
vae_hyperband/
â”œâ”€â”€ checkpoints/           # Autoâ€‘saved model & Ray Tune checkpoints
â”œâ”€â”€ logs/                  # TensorBoard event files
â”œâ”€â”€ best_config.png        # Visualised best hyperparams
â”œâ”€â”€ beta_vae_tsb.py        # Quick TB launch for Î²â€‘VAE runs
â”œâ”€â”€ model.ipynb            # Notebook: VAE + Î²â€‘VAE definition & demo
â”œâ”€â”€ slurm_job.sh           # Sample SLURM script (Ray on a cluster)
â”œâ”€â”€ tensorboard1.png       # Loss / KL curves
â”œâ”€â”€ tensorboard2.png       # Generated samples over epochs
â””â”€â”€ train_vae.py           # Main entry â€“ Rayâ€¯Tune HPO + training loop
```


---
## TensorBoard
asdf
![TensorBoard curves](vae_hyperband/tensorboard1.png)
![TensorBoard curves](vae_hyperband/tensorboard2.png)

---
## Best_config
![TensorBoard curves](vae_hyperband/best_config.png)

---

## Scaledâ€¯MLOpsÂ PipelineÂ (ðŸ“¦â€¯dataÂ â†’Â ðŸ§ Â modelÂ â†’Â ðŸ’¾Â checkpoints)

| Stage | File / Module | What It Does |
|-------|---------------|--------------|
| **Dataâ€¯Loading** | `train_vae.py â€º get_dataloader()`<br>`model.ipynb â€º DataÂ block` | *Single* source of truth for downloading Fashionâ€‘MNIST, normalizing, and wrapping it in a PyTorch `DataLoader`; works on CPU & GPU. |
| **Trainingâ€¯Loop** | `train_vae.py â€º train_epoch()` | Handles forward pass, reconstructionâ€¯+â€¯KL loss, backâ€‘prop, metric aggregation, and Rayâ€¯Tune callbacks. |
| **Validation** | `train_vae.py â€º eval_epoch()` | Runs every `config["val_interval"]` epochs; logs reconâ€¯loss & KL to TensorBoard. |
| **Checkpointing** | `train_vae.py â€º save_ckpt()`<br>Autoâ€‘handled by **Rayâ€¯Tune** | Saves `state_dict`, optimizer state, and epoch/step number in `checkpoints/`. Resume training via `--resume_ckpt path/to/file.pt`. |
| **ExperimentÂ Tracking** | TensorBoard (`runs/â€¦`)<br>Rayâ€¯Tune JSON logs | Scalars: recon_loss, KL_divergence, total_loss.<br>Images: input, reconstruction, randomÂ samples. |
| **ClusterÂ Execution** | `slurm_job.sh` | Portable SLURM scriptâ€”sets up Conda env, launches Rayâ€¯Tune with the correct GPU/CPU allocation, and pipes logs toÂ `logs/`. |

> **Why it matters:** these pieces turn a classroom demo into a **repeatable experiment pipeline**â€”you can stop/restart jobs, sweep hyperâ€‘parameters at scale, and visualise progress in real time.


