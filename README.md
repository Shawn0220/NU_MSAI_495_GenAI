# VAE from Scratch for Fashion Image Generation

 
**Summary:** Learn a clean latent representation of Fashionâ€‘MNIST with a **Variational Autoencoder (VAE)** (and its Î²â€‘VAE variant) and generate realistic fashion images.  
## Scaledâ€¯MLOpsÂ PipelineÂ (ðŸ“¦â€¯dataÂ â†’Â ðŸ§ Â modelÂ â†’Â ðŸ’¾Â checkpoints)

| Stage | Location (file) | Whatâ€™s inside |
|-------|-----------------|---------------|
| **Data loading** | `train_vae.py` | Reads Fashionâ€‘MNIST, applies transforms, wraps in `DataLoader` |
| **Model definition** | `model.ipynb` | Builds both vanilla VAE and Î²â€‘VAE modules in PyTorch |
| **Training loop** | `train_vae.py` | Runs forwardâ€‘pass, computes BCEâ€¯+â€¯KL (or Î²*KL), backâ€‘prop, and logs metrics |
| **Checkpoint save / load** | `train_vae.py` | Writes model parameters to file each epoch |
| **Hyperparameter tuning** | `train_vae.py` + `ray` | Rayâ€¯Tune explores latentâ€¯dim, learningâ€¯rate, batchâ€¯size and store results |
| **Experiment tracking** | `beta_vae_tsb.py` + TensorBoard | Script copies images/metrics into `runs/`; view with `tensorboard --logdir runs` |
| **Cluster execution** | `slurm_job.sh` | Singleâ€‘line submit (`sbatch`) sets up environment and launches Ray sweep on SLURM. |

> **Why it matters:** these pieces turn a classroom demo into a **repeatable experiment pipeline**â€”you can stop/restart jobs, sweep hyperâ€‘parameters at scale, and visualise progress in real time.

---

## Dataset

> **Fashionâ€‘MNIST** (Zalando Research) â€“ 70â€¯000 28Ã—28 grayscale images across 10 clothing classes (Tâ€‘shirt, trouser, sneaker, â€¦).  

---

## Model Architecture

| Part        | Layer(s) | Notes |
|-------------|----------|-------|
| **Encoder** | Convâ€¯(1â†’32,â€¯3Ã—3) â†’ ReLU â†’ Convâ€¯(32â†’64,â€¯3Ã—3) â†’ ReLU â†’ Flatten â†’ FC â†’ **Î¼**, **logâ€¯ÏƒÂ²** | |
| **Latent**  | 32â€‘D vector sampled via reparameterization trick | Latent dim swept over {16,â€¯32,â€¯64} |
| **Decoder** | FC â†’ reshape â†’ ConvTâ€¯(64â†’32) â†’ ReLU â†’ ConvTâ€¯(32â†’1) â†’ Sigmoid | |
| **Loss**    | **Binary Crossâ€‘Entropy** + **KLâ€‘divergence** | Î²â€‘VAE multiplies KL by Î² |

---

## Repository Structure

```text
vae_hyperband/
â”œâ”€â”€ checkpoints/           # Autoâ€‘saved model & Ray Tune checkpoints
â”œâ”€â”€ logs/                  # TensorBoard event files
â”œâ”€â”€ best_config.png        # Visualised best hyperparams
â”œâ”€â”€ beta_vae_tsb.py        # Quick TB launch for Î²â€‘VAE runs
â”œâ”€â”€ model.ipynb            # Notebook: VAE + Î²â€‘VAE definition & demo
â”œâ”€â”€ slurm_job.sh           # Sample SLURM script (Ray on a cluster)
â”œâ”€â”€ tensorboard1.png       # Loss / KL curves
â”œâ”€â”€ tensorboard2.png       # Generated samples over epochs
â””â”€â”€ train_vae.py           # Main entry â€“ Rayâ€¯Tune HPO + training loop
```


---
## TensorBoard
asdf
![TensorBoard curves](vae_hyperband/tensorboard1.png)
![TensorBoard curves](vae_hyperband/tensorboard2.png)

---
## Best_config
![TensorBoard curves](vae_hyperband/best_config.png)

---




